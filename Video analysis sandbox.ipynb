{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just show video from sequence\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\walking_77_image_sequence\\img (%d).jpg\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just show video\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\DSC_0077.MOV\")\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOG\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\DSC_0077.MOV\")\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        fgmask = fgbg.apply(frame)\n",
    "        cv2.imshow('image',fgmask)\n",
    "        key = cv2.waitKey(30) \n",
    "        if key == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOG2\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\DSC_0077.MOV\")\n",
    "\n",
    "subtractor = cv2.createBackgroundSubtractorMOG2(history=1000000, varThreshold=5, detectShadows=False)\n",
    "        \n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        mask = subtractor.apply(frame)\n",
    "        cv2.imshow(\"image\", mask)\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) D:\\Build\\OpenCV\\opencv-4.1.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8ea418504375>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DSC_0077.MOV\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfirst_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mfirst_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.0) D:\\Build\\OpenCV\\opencv-4.1.0\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "#Manual\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\DSC_0077.MOV\")\n",
    "_, first_frame = cap.read()\n",
    "first_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "first_gray = cv2.GaussianBlur(first_gray, (5, 5), 0)\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_frame = cv2.GaussianBlur(gray_frame, (5, 5), 0)\n",
    "        difference = cv2.absdiff(first_gray, gray_frame)\n",
    "        _, difference = cv2.threshold(difference, 25, 255, cv2.THRESH_BINARY)\n",
    "        cv2.imshow(\"image\", first_frame)\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        cv2.imshow(\"image\", difference)\n",
    "   \n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cornor detection normal image\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\DSC_0077.MOV\")\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        gray = np.float32(gray)\n",
    "        dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "        #result is dilated for marking the corners, not important\n",
    "        dst = cv2.dilate(dst,None)\n",
    "        # Threshold for an optimal value, it may vary depending on the image.\n",
    "        frame[dst>0.01*dst.max()]=[0,0,255]\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam detect marker(with highlight level threshold)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame, = cap.read()\n",
    "    if ret:\n",
    "        imgray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        imblur1 = cv2.medianBlur(imgray,5)\n",
    "        imblur2 = cv2.GaussianBlur(imblur1,(5,5),0)\n",
    "        \n",
    "        ret,thresh = cv2.threshold(imblur2,250,255,cv2.THRESH_BINARY)\n",
    "\n",
    "        contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        #print(\"Number of objects found = \", len(contours))\n",
    "       \n",
    "        \n",
    "        cv2.drawContours(frame, contours, -1, (0,0,255), 10)\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image edge detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "#cv2.resizeWindow('image', 2000,1242)\n",
    "cv2.resizeWindow('image', 560,996)\n",
    "\n",
    "img = cv2.imread('BAzmall.jpg',1)\n",
    "#img = cv2.imread('fap.png',1)\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(7,7),0)\n",
    "\n",
    "canny2 = cv2.Canny(blur, 50, 100)\n",
    "cv2.imshow(\"image\", canny2)\n",
    " \n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show marker coordinate in image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "        \n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 560,996)\n",
    "cv2.namedWindow('image2',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image2', 560,996)\n",
    "\n",
    "img = cv2.imread('FAzmall.jpg')\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imblur1 = cv2.medianBlur(imgray,5)\n",
    "imblur2 = cv2.GaussianBlur(imblur1,(5,5),0)\n",
    "\n",
    "ret,thresh = cv2.threshold(imblur2,250,255,cv2.THRESH_BINARY)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(\"Number of objects found = \", len(contours))\n",
    "\n",
    "i = 0\n",
    "for c in contours:\n",
    "    # calculate moments for each contour\n",
    "    M = cv2.moments(c)\n",
    "\n",
    "    # calculate x,y coordinate of center\n",
    "    if M[\"m00\"] != 0:\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "    else:\n",
    "        cX = 0\n",
    "        cY = 0\n",
    "\n",
    "    i+=1\n",
    "   # print('\\nX',i,' ',cX)\n",
    "    #print('Y',i,' ',cY)\n",
    "    centroid = \"X\"+str(i)+\":\"+str(cX)+\", Y\"+str(i)+\":\"+str(cY)\n",
    "    cv2.putText(img,centroid , (cX - 25, cY - 25),cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255, 255), 2)\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (0,0,255), 10)\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"image2\",thresh)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "if k == 27:         # wait for ESC key to exit\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save video\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "cv2.namedWindow('image',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1280,720)\n",
    "cap = cv2.VideoCapture(\"C:\\\\Users\\sunny.DESKTOP-QGFGEEK\\Desktop\\SGPtraining\\img (%d).jpg\")\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('77marked.avi',fourcc, 23.9, (1920,1080))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame, = cap.read()\n",
    "    if ret:\n",
    "        \n",
    "        #frame = cv2.flip(frame,0)\n",
    "\n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "        cv2.imshow(\"image\", frame)\n",
    "        \n",
    "        key = cv2.waitKey(30)\n",
    "        if key == 27:\n",
    "            break\n",
    "    else: \n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*7,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:7,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "images = cv2.VideoCapture(0)\n",
    "\n",
    "while(images.isOpened()):\n",
    "    ret, frame = images.read()\n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (7,6),None)\n",
    "        \n",
    "         # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            cv2.cornerSubPix(gray,corners,(11,11),(-1,-1),criteria)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            cv2.drawChessboardCorners(frame, (7,6), corners,ret)\n",
    "            \n",
    "        key = cv2.waitKey(100)\n",
    "        if key == 27:\n",
    "            break\n",
    "        cv2.imshow('frame',frame)\n",
    "    else: \n",
    "        break\n",
    "images.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) D:\\Build\\OpenCV\\opencv-4.1.0\\modules\\calib3d\\src\\calibration.cpp:3691: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-f55a3f51c598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.0) D:\\Build\\OpenCV\\opencv-4.1.0\\modules\\calib3d\\src\\calibration.cpp:3691: error: (-215:Assertion failed) nimages > 0 in function 'cv::calibrateCameraRO'\n"
     ]
    }
   ],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1],None,None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
